{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder, RobustScaler, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, SequentialFeatureSelector, VarianceThreshold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change working directory to project root\n",
    "if os.getcwd().split(\"/\")[-1] == \"notebooks\":\n",
    "    # Change working dir to project root\n",
    "    os.chdir(\"../\")\n",
    "    \n",
    "    # Print the current working directory\n",
    "    # print(f'Current Dir: {os.getcwd()}')\n",
    "    \n",
    "# Enable garbage collection\n",
    "gc.enable()\n",
    "\n",
    "# Configure display options for Pandas\n",
    "# (*) Helpful when displaying DFs w/ numerous features\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run notebooks/amex-feature-engineering.ipynb import load_dataset, features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/kyakovlev\n",
    "# https://www.kaggle.com/competitions/amex-default-prediction/discussion/327534\n",
    "def amex_score(y_true, y_pred):\n",
    "\n",
    "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz        = cum_pos_found / total_pos\n",
    "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
    "\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "\n",
    "def xgb__amex_metric(labels, predt):\n",
    "    score = 1 - amex_score(labels, predt)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preprocessor(X_train):\n",
    "    features = features_dict(X_train)\n",
    "\n",
    "    numeric_preprocessor = make_pipeline(\n",
    "        SimpleImputer(strategy='median', add_indicator=True))\n",
    "\n",
    "    categorical_preprocessor = make_pipeline(\n",
    "        SimpleImputer(strategy='most_frequent', add_indicator=True),\n",
    "        OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "\n",
    "    ordinal_preprocessor = make_pipeline(\n",
    "        SimpleImputer(strategy='constant', fill_value=-1, add_indicator=True),\n",
    "        OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-11))\n",
    "\n",
    "    feature_preprocessor = ColumnTransformer([\n",
    "            ('numeric', numeric_preprocessor, features['numeric']),\n",
    "            ('categorical', categorical_preprocessor, features['categorical'])\n",
    "        ], verbose_feature_names_out=True)\n",
    "\n",
    "    feature_selector = SelectFromModel(\n",
    "        RandomForestClassifier(\n",
    "            n_estimators=25,\n",
    "            random_state=1123), \n",
    "        max_features=750)\n",
    "\n",
    "    preprocessor_pipeline = make_pipeline(\n",
    "        feature_preprocessor)\n",
    "    \n",
    "    return preprocessor_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Version: 1.6.1\n"
     ]
    }
   ],
   "source": [
    "# Print version of XGBoost used\n",
    "print(f'XGB Version: {xgb.__version__}')\n",
    "\n",
    "# Instantiate the XGBClassifier\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    booster='dart',\n",
    "    use_label_encoder=False,\n",
    "    max_depth=7,\n",
    "    early_stopping_rounds=5,\n",
    "    learning_rate=0.1,\n",
    "    feval=amex_score,\n",
    "    eval_metric=xgb__amex_metric,\n",
    "    verbosity=3,\n",
    "    seed=1123, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "amex_train__agg = (load_dataset('train_agg', use_feather=True)\n",
    "                   .replace([np.inf, -np.inf], np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    amex_train__agg.drop('target', axis=1), \n",
    "    amex_train__agg.target,\n",
    "    stratify=amex_train__agg.target,\n",
    "    test_size=0.20,\n",
    "    random_state=1123)\n",
    "\n",
    "del amex_train__agg\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Features - Count(#): 1424\n",
      "Categorical Features - Count(#): 20\n",
      "Ordinal Features - Count(#): 0\n"
     ]
    }
   ],
   "source": [
    "feature_preprocessor = make_preprocessor(X_train)\n",
    "\n",
    "feature_preprocessor.fit(X_train, y_train)\n",
    "\n",
    "X_train__preprocessed = feature_preprocessor.transform(X_train)\n",
    "X_test__preprocessed = feature_preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:17:36] DEBUG: /home/conda/feedstock_root/build_artifacts/xgboost-split_1660208814268/work/src/gbm/gbtree.cc:155: Using tree method: 2\n",
      "[23:18:33] INFO: /home/conda/feedstock_root/build_artifacts/xgboost-split_1660208814268/work/src/tree/updater_prune.cc:101: tree pruning end, 244 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[23:18:33] INFO: /home/conda/feedstock_root/build_artifacts/xgboost-split_1660208814268/work/src/gbm/gbtree.cc:909: drop 0 trees, weight = 1\n",
      "[0]\tvalidation_0-logloss:0.62985\tvalidation_0-xgb__amex_metric:0.28932\n",
      "[23:19:03] INFO: /home/conda/feedstock_root/build_artifacts/xgboost-split_1660208814268/work/src/tree/updater_prune.cc:101: tree pruning end, 240 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[23:19:03] INFO: /home/conda/feedstock_root/build_artifacts/xgboost-split_1660208814268/work/src/gbm/gbtree.cc:909: drop 0 trees, weight = 1\n",
      "[1]\tvalidation_0-logloss:0.57790\tvalidation_0-xgb__amex_metric:0.27708\n",
      "[23:19:37] INFO: /home/conda/feedstock_root/build_artifacts/xgboost-split_1660208814268/work/src/tree/updater_prune.cc:101: tree pruning end, 232 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[23:19:37] INFO: /home/conda/feedstock_root/build_artifacts/xgboost-split_1660208814268/work/src/gbm/gbtree.cc:909: drop 0 trees, weight = 1\n",
      "[2]\tvalidation_0-logloss:0.53453\tvalidation_0-xgb__amex_metric:0.27079\n",
      "[23:20:05] INFO: /home/conda/feedstock_root/build_artifacts/xgboost-split_1660208814268/work/src/tree/updater_prune.cc:101: tree pruning end, 244 extra nodes, 0 pruned nodes, max_depth=7\n",
      "[23:20:05] INFO: /home/conda/feedstock_root/build_artifacts/xgboost-split_1660208814268/work/src/gbm/gbtree.cc:909: drop 0 trees, weight = 1\n",
      "[3]\tvalidation_0-logloss:0.49797\tvalidation_0-xgb__amex_metric:0.26581\n"
     ]
    }
   ],
   "source": [
    "# Fit the classifier to the training set\n",
    "xgb_clf.fit(X_train__preprocessed, y_train, \n",
    "            eval_set=[(X_test__preprocessed, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels of the test set: preds\n",
    "train_preds = xgb_clf.predict(X_train__preprocessed)\n",
    "test_preds = xgb_clf.predict(X_test__preprocessed)\n",
    "\n",
    "train_score = amex_score(y_train.values, train_preds)\n",
    "test_score = amex_score(y_test.values, test_preds)\n",
    "\n",
    "print(f'Train Score: {train_score}')\n",
    "print(f'Test Score: {test_score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('amex_v2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "790edd3242a40ac70c58114a122b744731b030acc406feafcec626ff57999bc9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
