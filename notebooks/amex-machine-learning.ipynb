{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import (\n",
    "    LabelEncoder,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    RobustScaler,\n",
    "    StandardScaler,\n",
    ")\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "from sklearn.feature_selection import (\n",
    "    SelectFromModel,\n",
    "    SelectKBest,\n",
    "    SequentialFeatureSelector,\n",
    "    VarianceThreshold,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change working directory to project root\n",
    "if os.getcwd().split(\"/\")[-1] == \"notebooks\":\n",
    "    # Change dir to parent directory.\n",
    "    os.chdir(\"../\")\n",
    "    # Print the current working directory\n",
    "    print(f'Current Dir: {os.getcwd()}')\n",
    "    \n",
    "# Enable garbage collection\n",
    "gc.enable()\n",
    "\n",
    "# > Configure display options for Pandas\n",
    "# ---------------------------------------------------------------\n",
    "# Set display width to 1000.\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "# Set maximum number of rows to display to 500.\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "# Set maximum number of columns to display to 500.\n",
    "pd.set_option(\"display.max_columns\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run notebooks/amex-feature-engineering.ipynb import load_dataset, features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/kyakovlev\n",
    "# https://www.kaggle.com/competitions/amex-default-prediction/discussion/327534\n",
    "def amex_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    > The function takes in the true labels and the predicted labels, and returns the evaluation  score. (TODO: correct the following passage) The evaluation metric is the average of the Gini coefficient and the top 4% score\n",
    "\n",
    "    Args:\n",
    "      y_true: the true labels\n",
    "      y_pred: the predicted probabilities of the positive class\n",
    "\n",
    "    Returns:\n",
    "      the score of the model.\n",
    "    \"\"\"\n",
    "    labels = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights = np.where(labels[:, 0] == 0, 20, 1)\n",
    "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four = np.sum(cut_vals[:, 0]) / np.sum(labels[:, 0])\n",
    "\n",
    "    gini = [0, 0]\n",
    "    for i in [1, 0]:\n",
    "        labels = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight = np.where(labels[:, 0] == 0, 20, 1)\n",
    "        weight_random = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos = np.sum(labels[:, 0] * weight)\n",
    "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz = cum_pos_found / total_pos\n",
    "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "\n",
    "    # Returning the average of the Gini coefficient and the top 4% score.\n",
    "    return 0.5 * (gini[1] / gini[0] + top_four)\n",
    "\n",
    "\n",
    "def xgb__amex_metric(labels, predt):\n",
    "    \"\"\"\n",
    "    It takes in the actual values and the predicted values and returns the score\n",
    "\n",
    "    Args:\n",
    "      labels: the actual values of the target variable\n",
    "      predt: the predictions from the model\n",
    "\n",
    "    Returns:\n",
    "      the score of the model.\n",
    "    \"\"\"\n",
    "    score = 1 - amex_score(labels, predt)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preprocessor(X_train):\n",
    "    \"\"\"\n",
    "    It takes the training dataset as input and returns a pipeline that can be used to\n",
    "    preprocess the training data and the test data.\n",
    "\n",
    "    Args:\n",
    "      X_train: The training data\n",
    "\n",
    "    Returns:\n",
    "      A pipeline object\n",
    "    \"\"\"\n",
    "    # Creating a dictionary of the features in the training set.\n",
    "    features = features_dict(X_train)\n",
    "\n",
    "    # Impute missing values in numeric features with their median values and then adding an indicator column to indicate which values were imputed.\n",
    "    numeric_preprocessor = make_pipeline(\n",
    "        SimpleImputer(strategy=\"median\", add_indicator=True)\n",
    "    )\n",
    "\n",
    "    # Impute missing values in categorical features with their most frequent value before one-hot-encoding the categorical features.\n",
    "    categorical_preprocessor = make_pipeline(\n",
    "        SimpleImputer(strategy=\"most_frequent\", add_indicator=True),\n",
    "        OneHotEncoder(handle_unknown=\"ignore\", sparse=False),\n",
    "    )\n",
    "\n",
    "    # Impute missing values in ordinal features with -1 and then encoding the ordinal features.\n",
    "    ordinal_preprocessor = make_pipeline(\n",
    "        SimpleImputer(strategy=\"constant\", fill_value=-1, add_indicator=True),\n",
    "        OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-11),\n",
    "    )\n",
    "\n",
    "    # Make ColumnTransformer to combine various numeric/categorical transformers\n",
    "    feature_preprocessor = ColumnTransformer(\n",
    "        [\n",
    "            (\"numeric\", numeric_preprocessor, features[\"numeric\"]),\n",
    "            (\"categorical\", categorical_preprocessor, features[\"categorical\"]),\n",
    "        ],\n",
    "        verbose_feature_names_out=True,\n",
    "    )\n",
    "\n",
    "    # Select the top 750 features from the training set using the Random Forest Classifier.\n",
    "    feature_selector = SelectFromModel(\n",
    "        RandomForestClassifier(n_estimators=25, random_state=1123), max_features=750\n",
    "    )\n",
    "\n",
    "    # Make the final pipeline to preprocess the training and test datasets.\n",
    "    preprocessor_pipeline = make_pipeline(feature_preprocessor)\n",
    "\n",
    "    # Return the pipeline object.\n",
    "    return preprocessor_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print version of XGBoost used\n",
    "print(f\"XGB Version: {xgb.__version__}\")\n",
    "\n",
    "# Instantiate the XGBClassifier\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    booster=\"dart\",\n",
    "    use_label_encoder=False,\n",
    "    max_depth=7,\n",
    "    early_stopping_rounds=5,\n",
    "    subsample=0.88,\n",
    "    colsample_bytree=0.72,\n",
    "    n_estimators=128,\n",
    "    learning_rate=0.32,\n",
    "    feval=amex_score,\n",
    "    eval_metric=xgb__amex_metric,\n",
    "    verbosity=3,\n",
    "    seed=1123,\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data from the `data/processed` directory.\n",
    "amex_train__agg = load_dataset(\"train_agg\", use_feather=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    amex_train__agg.drop(\"target\", axis=1),\n",
    "    amex_train__agg.target,\n",
    "    stratify=amex_train__agg.target,\n",
    "    test_size=0.20,\n",
    "    random_state=1123,\n",
    ")\n",
    "\n",
    "# Delete the `amex_train__agg` variable and then call the garbage collector to free up memory.\n",
    "del amex_train__agg\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a pipeline object that can be used to preprocess the training and test datasets.\n",
    "feature_preprocessor = make_preprocessor(X_train)\n",
    "\n",
    "# Fit the preprocessor to the training data.\n",
    "feature_preprocessor.fit(X_train, y_train)\n",
    "\n",
    "# Preprocess the training and test datasets.\n",
    "X_train__preprocessed = feature_preprocessor.transform(X_train)\n",
    "X_test__preprocessed = feature_preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the classifier to the training set\n",
    "xgb_clf.fit(X_train__preprocessed, y_train, eval_set=[(X_test__preprocessed, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the probabilities for the positive class in the training and test datasets.\n",
    "train_preds = xgb_clf.predict_proba(X_train__preprocessed)[:, 1]\n",
    "test_preds = xgb_clf.predict_proba(X_test__preprocessed)[:, 1]\n",
    "\n",
    "# Calculate the evaluation metric for the training and test datasets.\n",
    "train_score = amex_score(y_train.values, train_preds)\n",
    "test_score = amex_score(y_test.values, test_preds)\n",
    "\n",
    "# Print model scores for both the training and test datasets.\n",
    "print(f\"Train Score: {train_score}\")\n",
    "print(f\"Test Score: {test_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the `feature_preprocessor` object to a file called `feature_preprocessor.pkl` in the `models` directory.\n",
    "with open(\"models/feature_preprocessor.pkl\", \"wb\") as f:\n",
    "    pickle.dump(feature_preprocessor, f)\n",
    "\n",
    "# Save the `xgb_clf` object to a file called `xgb_clf.pkl` in the `models` directory.\n",
    "with open(\"models/xgb_clf.pkl\", \"wb\") as f:\n",
    "    pickle.dump(xgb_clf, f)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "28ed4e3bfc6dbc0ee6f9216b9beca2c6fff623d080b9c5b8a874eb933f3db8ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
