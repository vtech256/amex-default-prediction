{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://www.kaggle.com/code/munumbutt/simple-lgbm-starter/notebook\n",
    "\n",
    "def amex_metric(y_true, y_pred) -> float:\n",
    "    if isinstance(y_true, (pd.Series, np.ndarray)):\n",
    "        y_true = pd.DataFrame(y_true)\n",
    "    if isinstance(y_pred, (pd.Series, np.ndarray)):\n",
    "        y_pred = pd.DataFrame(y_pred, columns=['prediction'])\n",
    "    \n",
    "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "        \n",
    "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
    "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
    "\n",
    "    g = normalized_weighted_gini(y_true, y_pred)\n",
    "    d = top_four_percent_captured(y_true, y_pred)\n",
    "\n",
    "    return 0.5 * (g + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://www.kaggle.com/code/werus23/amex-feature-engineering\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_amex(y_pred, y_true):\n",
    "    return 'amex', amex_metric_np(y_pred,y_true.get_label())\n",
    "\n",
    "# Created by https://www.kaggle.com/yunchonggan\n",
    "# https://www.kaggle.com/competitions/amex-default-prediction/discussion/328020\n",
    "def amex_metric_np(preds: np.ndarray, target: np.ndarray) -> float:\n",
    "    indices = np.argsort(preds)[::-1]\n",
    "    preds, target = preds[indices], target[indices]\n",
    "\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_mask = cum_norm_weight <= 0.04\n",
    "    d = np.sum(target[four_pct_mask]) / np.sum(target)\n",
    "\n",
    "    weighted_target = target * weight\n",
    "    lorentz = (weighted_target / weighted_target.sum()).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "\n",
    "    n_pos = np.sum(target)\n",
    "    n_neg = target.shape[0] - n_pos\n",
    "    gini_max = 10 * n_neg * (n_pos + 20 * n_neg - 19) / (n_pos + 20 * n_neg)\n",
    "\n",
    "    g = gini / gini_max\n",
    "    return 0.5 * (g + d)\n",
    "\n",
    "# https://www.kaggle.com/kyakovlev\n",
    "# https://www.kaggle.com/competitions/amex-default-prediction/discussion/327534\n",
    "def amex_score(y_true, y_pred):\n",
    "\n",
    "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz        = cum_pos_found / total_pos\n",
    "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
    "\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "\n",
    "def xgb__amex_metric(labels, predt):\n",
    "    score = 1 - amex_score(labels, predt)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "                .assign(\n",
    "                    S_2_Day = dataset['S_2'].dt.day.astype('category'),\n",
    "                    S_2_Month = dataset['S_2'].dt.month.astype('category'),\n",
    "                    S_2_Year = dataset['S_2'].dt.year.astype('category'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Load compressed datasets\n",
    "# Source: https://www.kaggle.com/datasets/munumbutt/amexfeather\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amex_train__agg = load_amex('train_agg').set_index('customer_ID')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    amex_train__agg.drop('target', axis=1), \n",
    "    amex_train__agg.target,\n",
    "    stratify=amex_train__agg.target,\n",
    "    test_size=0.20,\n",
    "    random_state=1123)\n",
    "\n",
    "del amex_train__agg, amex_test__agg\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = reduce_mem_usage(X_train)\n",
    "X_test = reduce_mem_usage(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "IterativeImputer(\n",
    "        initial_strategy='median',\n",
    "        sample_posterior=True,\n",
    "        max_iter=2,\n",
    "        add_indicator=True, \n",
    "        random_state=1123)\n",
    "\n",
    "SimpleImputer(strategy='mean', add_indicator=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train_df = load_amex('train_agg', use_feather=True)\n",
    "\n",
    "y_train = train_df.target\n",
    "X_train = train_df.drop('target', axis=1)\n",
    "\n",
    "del train_df\n",
    "gc.collect()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "log_reg = make_pipeline(\n",
    "    preprocessor_pipeline, \n",
    "    SelectKBest(k=128), \n",
    "    LogisticRegression())\n",
    "\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "train_score = amex_metric(y_train, log_reg.predict_proba(X_train)[:, 0])\n",
    "test_score = amex_metric(y_test, log_reg.predict_proba(X_test)[:, 0])\n",
    "\n",
    "print(f'Train Score: {train_score}')\n",
    "print(f'Test Score: {test_score}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "rf_clf = make_pipeline(\n",
    "    preprocessor_pipeline,\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=25, \n",
    "        random_state=1123,\n",
    "        n_jobs=5))\n",
    "\n",
    "# Fit the classifier to the training set\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set: preds\n",
    "train_preds = rf_clf.predict(X_train)\n",
    "test_preds = rf_clf.predict(X_test)\n",
    "\n",
    "train_score = amex_score(y_train.values, train_preds)\n",
    "test_score = amex_score(y_test.values, test_preds)\n",
    "\n",
    "print(f'Train Score: {train_score}')\n",
    "print(f'Test Score: {test_score}')\n",
    "\n",
    "with open('models/rf_clf.pkl','wb') as f:\n",
    "    pickle.dump(rf_clf, f)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SelectFromModel(\n",
    "        rf_clf,\n",
    "        prefit=True,\n",
    "        max_features=512),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DMatrix: housing_dmatrix\n",
    "#train_dmatrix = xgb.DMatrix(data=X_train, label=y_train)\n",
    "\n",
    "# Create the parameter dictionary for each tree: params \n",
    "xgb_params = {\"objective\": \"binary:logistic\", \n",
    "              \"booster\": \"dart\",\n",
    "              \"use_label_encoder\": False,\n",
    "              \"max_depth\": 4,\n",
    "              \"learning_rate\": 0.032,\n",
    "              \"subsample\": 0.80,\n",
    "              \"colsample_bytree\": 0.64,\n",
    "              \"custom_metric\": amex_score,\n",
    "              \"early_stopping_rounds\": 5,\n",
    "              \"eval_metric\": xgb__amex_metric,\n",
    "              \"feval\": xgb_amex,\n",
    "              \"gamma\": 1.12,\n",
    "              \"verbosity\": 3,\n",
    "              \"seed\": 1123}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "with open('models/xgb_clf.pkl','wb') as f:\n",
    "    pickle.dump(xgb_clf, f)\n",
    "def amex_scorer_func(estimator, X, y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    return amex_score(y, y_pred)\n",
    "\n",
    "amex_scorer = make_scorer(amex_score)\n",
    "\n",
    "cv_kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=1123)\n",
    "\n",
    "score = cross_val_score(\n",
    "    xgb_clf, \n",
    "    X_train, \n",
    "    y_train, \n",
    "    scoring=amex_scorer, \n",
    "    cv=cv_kfold)\n",
    "print(f'AMEX Score (Cross Validated): {score}')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1123)\n",
    "\n",
    "skf_scores = []\n",
    "skf_amex_scores = []\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "    X_train_fold, y_train_fold = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "    X_test_fold, y_test_fold = X_train.iloc[test_index], y_train.iloc[test_index]\n",
    "    \n",
    "    xgb_clf.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    score = xgb_clf.score(X_test_fold, y_test_fold)\n",
    "    print(score)\n",
    "    skf_scores.append(score)\n",
    "    skf_amex_scores.append((\n",
    "        amex_score(y_train_fold, xgb_clf.predict(X_train_fold)),\n",
    "        amex_score(y_test_fold, xgb_clf.predict(X_test_fold))\n",
    "    ))\n",
    "print(skf_scores)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test predictions to file\n",
    "def make_submission(estimator, save_csv=True):\n",
    "    X_test = load_amex('test_agg')\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'customer_ID': X_test.index,\n",
    "        'target': y_pred})\n",
    "    \n",
    "    if save_csv:\n",
    "        submission.to_csv('.data/processed/kaggle_submission.csv', index=False)\n",
    "    if gc:\n",
    "        del X_test, y_pred\n",
    "        gc.collect()\n",
    "\n",
    "    return submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6253b0757717560d5dcadf36acf1738a8f43823bd2758e22944cdc4c86c7691f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
