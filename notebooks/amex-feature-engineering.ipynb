{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Dir: /home/victor/amex-default-prediction\n"
     ]
    }
   ],
   "source": [
    "# Change working directory to project root\n",
    "if os.getcwd().split(\"/\")[-1] == \"notebooks\":\n",
    "    # Change working dir to project root\n",
    "    os.chdir(\"../\")\n",
    "    \n",
    "    # Print the current working directory\n",
    "    print(f'Current Dir: {os.getcwd()}')\n",
    "    \n",
    "# Enable garbage collection\n",
    "gc.enable()\n",
    "\n",
    "# Configure display options for Pandas\n",
    "# (*) Helpful when displaying DFs w/ numerous features\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset, use_feather=True):\n",
    "    # Function to load amex data\n",
    "    # Raw Data - Source: American Express via Kaggle\n",
    "    # Reduced  - Source: https://www.kaggle.com/datasets/munumbutt/amexfeather\n",
    "    valid_datasets = (\"train\", \"test\", \"train_agg\", \"test_agg\")\n",
    "    if not isinstance(dataset, str):\n",
    "        raise TypeError\n",
    "    elif dataset not in valid_datasets:\n",
    "        raise ValueError\n",
    "    fpaths = {\n",
    "        \"feather\": {\n",
    "            \"train\": \"./data/external/compressed/train_data.ftr\",\n",
    "            \"test\": \"./data/external/compressed/test_data.ftr\",\n",
    "            \"train_agg\": \"./data/interim/train_agg.ftr\",\n",
    "            \"test_agg\": \"./data/interim/test_agg.ftr\",\n",
    "        },\n",
    "        \"csv\": {\n",
    "            \"train\": \"./data/raw/train_data.csv\",\n",
    "            \"test\": \"./data/raw/test_data.csv\",\n",
    "            \"train_agg\": \"./data/interim/train_agg.csv\",\n",
    "            \"test_agg\": \"./data/interim/test_agg.csv\",\n",
    "        },\n",
    "    }\n",
    "    if use_feather:\n",
    "        feather_file = fpaths[\"feather\"].get(dataset)\n",
    "        return pd.read_feather(feather_file).set_index(\"customer_ID\")\n",
    "    else:\n",
    "        csv_file = fpaths[\"csv\"].get(dataset)\n",
    "        return pd.read_csv(csv_file, index_col=\"customer_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_incomplete_features(amex_dataset, threshold=0.85, verbose=True):\n",
    "    if not isinstance(threshold, (float, int)):\n",
    "        raise TypeError()\n",
    "    elif (threshold < 0) or (threshold > 1):\n",
    "        raise ValueError()\n",
    "    pct_incomplete = amex.isnull().sum().div(len(amex)).sort_values(ascending=False)\n",
    "    incomplete_features = set(\n",
    "        pct_incomplete[pct_incomplete >= threshold].index.tolist()\n",
    "    )\n",
    "    if verbose:\n",
    "        print(f\"Incomplete Features >= {threshold}%:\\n{incomplete_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agg_features(amex_dataset):\n",
    "    amex_numeric = amex_dataset.select_dtypes(include=\"number\")\n",
    "\n",
    "    last_statement = amex_numeric.groupby(\"customer_ID\").nth(-1)\n",
    "    first_statement = amex_numeric.groupby(\"customer_ID\").nth(0)\n",
    "\n",
    "    lag_div = last_statement.div(first_statement).fillna(1)\n",
    "    lag_diff = last_statement.subtract(first_statement).fillna(0)\n",
    "\n",
    "    lag_div.columns = [col + \"__lag_div\" for col in lag_div.columns]\n",
    "    lag_diff.columns = [col + \"__lag_diff\" for col in lag_diff.columns]\n",
    "\n",
    "    numeric__agg_lag = pd.concat([lag_diff, lag_div], axis=1).replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    numeric__agg = amex_numeric.groupby(\"customer_ID\").agg(\n",
    "        [\"first\", \"last\", \"mean\", \"min\", \"max\", \"std\", \"sem\"]\n",
    "    )\n",
    "    numeric__agg.columns = [\"__\".join(col) for col in numeric__agg.columns]\n",
    "\n",
    "    categorical__agg = (\n",
    "        amex_dataset.select_dtypes(include=\"category\")\n",
    "        .groupby(\"customer_ID\")\n",
    "        .agg([\"first\", \"last\", \"count\", \"nunique\"])\n",
    "    )\n",
    "    categorical__agg.columns = [\"__\".join(col) for col in categorical__agg.columns]\n",
    "\n",
    "    amex_agg = pd.concat([categorical__agg, numeric__agg, numeric__agg_lag], axis=1)\n",
    "\n",
    "    return amex_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(amex_dataset):\n",
    "    incomplete_features = {\n",
    "        'D_87', 'D_88', 'D_108', 'D_110', 'D_111', 'B_39', \n",
    "        'D_73', 'B_42', 'D_134', 'D_137', 'D_135', 'D_138', \n",
    "        'D_136', 'R_9', 'B_29', 'D_106', 'D_132', 'D_49', \n",
    "        'R_26', 'D_76', 'D_66', 'D_42'}\n",
    "    made_redundant = {'S_2'}\n",
    "    target_variable = {'target'}\n",
    "\n",
    "    invalid_cols = (incomplete_features | made_redundant | target_variable)\n",
    "    cols_to_drop = (amex_dataset\n",
    "                    .columns\n",
    "                    .intersection(invalid_cols)\n",
    "                    .tolist())\n",
    "\n",
    "    amex_aggregated = (amex_dataset\n",
    "                       .drop(cols_to_drop, axis=1)\n",
    "                       .pipe(create_agg_features))\n",
    "        \n",
    "    if 'target' in cols_to_drop:\n",
    "        amex_aggregated['target'] = (\n",
    "            amex_dataset.groupby('customer_ID').tail(1).target)\n",
    "    return amex_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datasets(read_feather=True, to_feather=True, to_csv=False):\n",
    "    train_agg = (load_dataset('train', use_feather=read_feather)\n",
    "                 .pipe(make_features))\n",
    "    test_agg = (load_dataset(\"test\", use_feather=read_feather)\n",
    "                .pipe(make_features))\n",
    "    \n",
    "    if to_feather:\n",
    "        train_agg.reset_index().to_feather('./data/interim/train_agg.ftr')\n",
    "        test_agg.reset_index().to_feather('./data/interim/test_agg.ftr')\n",
    "        \n",
    "    if to_csv:\n",
    "        train_agg.to_csv('./data/interim/train_agg.csv')\n",
    "        test_agg.to_csv('./data/interim/test_agg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_dict(X_train, verbose=True):\n",
    "    numeric_features = (X_train\n",
    "                        .select_dtypes(include='number')\n",
    "                        .columns\n",
    "                        .tolist())\n",
    "\n",
    "    categorical_features = (X_train\n",
    "                            .select_dtypes(include='category')\n",
    "                            .columns\n",
    "                            .tolist())\n",
    "\n",
    "    ordinal_features = []\n",
    "    \n",
    "    all_features = X_train.columns.tolist()\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Numeric Features - Count(#): {len(numeric_features)}')\n",
    "        print(f'Categorical Features - Count(#): {len(categorical_features)}')\n",
    "        print(f'Ordinal Features - Count(#): {len(ordinal_features)}')\n",
    "    \n",
    "    return {\n",
    "        'num': numeric_features,\n",
    "        'cat': categorical_features,\n",
    "        'ord': ordinal_features,\n",
    "        'all': all_features,\n",
    "        'numeric': numeric_features,\n",
    "        'categorical': categorical_features,\n",
    "        'ordinal': ordinal_features,\n",
    "        'all_features': all_features\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 ('amex_v2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "790edd3242a40ac70c58114a122b744731b030acc406feafcec626ff57999bc9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
